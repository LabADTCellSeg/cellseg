{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55fc1c94-d822-4aea-8bff-8f493e7d4802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import albumentations as albu\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import segmentation_models_pytorch.utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "from cellseg_utils import (\n",
    "    get_training_augmentation,\n",
    "    get_validation_augmentation,\n",
    "    get_preprocessing,\n",
    "    get_all_fp_data,\n",
    "    CellDataset4,\n",
    "    split_image,\n",
    "    get_squares,\n",
    "    unsplit_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ae8aeb-255a-4c88-9a04-1bd2b2172865",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+2024-05-05-LF1-p6-sl2',\n",
       " '+2024-05-06-LF1-p12',\n",
       " '+2024-05-06-LF1p9-sl2',\n",
       " '+2024-05-07-LF1p15',\n",
       " '+2024-05-08-LF1p18sl2',\n",
       " '+2024-05-31-LF1-p22',\n",
       " 'test.pt',\n",
       " 'train.pt',\n",
       " 'val.pt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = Path('datasets/Cells_2.0_for_Ivan/masked_MSC')\n",
    "dir01 = root_dir / 'pics 2024-20240807T031703Z-001' / 'pics 2024'\n",
    "dir02 = root_dir / 'pics 2024-20240807T031703Z-002' / 'pics 2024'\n",
    "\n",
    "lf_dir = dir01 / 'LF1'\n",
    "\n",
    "exps_dir_list = list()\n",
    "for v in lf_dir.iterdir():\n",
    "    exps_dir_list.append(v.name)\n",
    "exps_dir_list.sort()\n",
    "exps_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070708c1-49f8-44b7-b919-1929b37f9556",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = lf_dir\n",
    "exp_class_dict = {'+2024-05-05-LF1-p6-sl2': 6,\n",
    "                  '+2024-05-06-LF1-p12': 12,\n",
    "                  '+2024-05-06-LF1p9-sl2': 9,\n",
    "                  '+2024-05-07-LF1p15': 15,\n",
    "                  '+2024-05-08-LF1p18sl2': 18,\n",
    "                  '+2024-05-31-LF1-p22': 22\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b8cec54-06d1-4389-b99d-c88f011daca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_fp_data = get_all_fp_data(dataset_dir, exp_class_dict)\n",
    "all_fp_data = all_fp_data[:10]\n",
    "total_len = len(all_fp_data)\n",
    "train_num = int(total_len * 0.7)\n",
    "val_num = int(total_len * 0.2)\n",
    "test_num = total_len - val_num\n",
    "\n",
    "random.shuffle(all_fp_data)\n",
    "\n",
    "train_fp_data = all_fp_data[:train_num]\n",
    "val_fp_data = all_fp_data[train_num:train_num+val_num]\n",
    "test_fp_data = all_fp_data[train_num+val_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4fdba1-0783-4e66-8437-03d870e50107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_img = Image.open(all_fp_data[0]['mask_fp'])\n",
    "w, h = mask_img.size[0], mask_img.size[1]\n",
    "w, h = int(w/2), int(h/2)\n",
    "square_a = 512\n",
    "border = 10\n",
    "\n",
    "ENCODER = 'timm-efficientnet-b0'  # 'resnet101',  # 'efficientnet-b2',  # 'timm-efficientnet-b8',  # 'efficientnet-b0'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "\n",
    "target_size = (w, h)\n",
    "square_w, square_h = square_a, square_a\n",
    "square_size = (square_w, square_h)\n",
    "\n",
    "# full_size, full_size_with_borders, squares = get_squares(target_size,\n",
    "#                                                          square_size,\n",
    "#                                                          border)\n",
    "\n",
    "full_size, squares = None, None\n",
    "add_shadow_to_img = True\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "preprocessing_fn = None\n",
    "preprocessing = get_preprocessing(preprocessing_fn)\n",
    "\n",
    "train_dataset = CellDataset4(train_fp_data,\n",
    "                      exp_class_dict,\n",
    "                      full_size=full_size,\n",
    "                      add_shadow_to_img=add_shadow_to_img,\n",
    "                      squares=squares,\n",
    "                      border=border,\n",
    "                      channels=None,\n",
    "                      classes_num=2,\n",
    "                      augmentation=get_training_augmentation(target_size=target_size),\n",
    "                      preprocessing=preprocessing,\n",
    "                      classes=None,\n",
    "                      target_size=target_size\n",
    "                      )\n",
    "\n",
    "val_dataset = CellDataset4(val_fp_data,\n",
    "                      exp_class_dict,\n",
    "                      full_size=full_size,\n",
    "                      add_shadow_to_img=add_shadow_to_img,\n",
    "                      squares=squares,\n",
    "                      border=border,\n",
    "                      channels=None,\n",
    "                      classes_num=2,\n",
    "                      augmentation=get_validation_augmentation(target_size=target_size),\n",
    "                      preprocessing=preprocessing,\n",
    "                      classes=None,\n",
    "                      target_size=target_size\n",
    "                      )\n",
    "\n",
    "test_dataset = CellDataset4(test_fp_data,\n",
    "                      exp_class_dict,\n",
    "                      full_size=full_size,\n",
    "                      add_shadow_to_img=add_shadow_to_img,\n",
    "                      squares=squares,\n",
    "                      border=border,\n",
    "                      channels=None,\n",
    "                      classes_num=2,\n",
    "                      augmentation=get_validation_augmentation(target_size=target_size),\n",
    "                      preprocessing=preprocessing,\n",
    "                      classes=None,\n",
    "                      target_size=target_size\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bea00f5-b837-419c-b26c-c96f5c3a3f12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:05<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# torch.save(train_dataset, lf_dir / 'train.pt')\n",
    "# del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4ad5398-a2b0-4f6e-a6cc-ef145b26c962",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# torch.save(val_dataset, lf_dir / 'val.pt')\n",
    "# del val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "632625b1-cc5b-40c8-995c-44f00e7c4ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CellDataset4(test_fp_data,\n",
    "                      exp_class_dict,\n",
    "                      full_size=full_size,\n",
    "                      add_shadow_to_img=add_shadow_to_img,\n",
    "                      squares=squares,\n",
    "                      border=border,\n",
    "                      channels=None,\n",
    "                      classes_num=2,\n",
    "                      augmentation=get_validation_augmentation(target_size=target_size),\n",
    "                      preprocessing=preprocessing,\n",
    "                      classes=None,\n",
    "                      target_size=target_size\n",
    "                      )\n",
    "# torch.save(test_dataset, lf_dir / 'test.pt')\n",
    "# del test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02f20e60-e72f-4f48-b9cb-f54621ec8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = torch.load(lf_dir / 'train.pt')\n",
    "# val_dataset = torch.load(lf_dir / 'val.pt')\n",
    "# test_dataset = torch.load(lf_dir / 'test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3e6827e-bc8a-48f1-95fe-d61a90ff4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# full_img, full_mask = train_dataset[idx]\n",
    "\n",
    "# full_img_ = Image.fromarray((full_img[:3].transpose(1, 2, 0)).astype('uint8')).resize(target_size)\n",
    "# display(full_img_)\n",
    "\n",
    "# full_img_ = Image.fromarray((np.stack([full_img[-1]]*3, axis=-1)).astype('uint8')).resize(target_size)\n",
    "# display(full_img_)\n",
    "\n",
    "# # for idx in range(full_img.shape[0]):\n",
    "# #     img = Image.fromarray((np.stack([full_img[idx]]*3, axis=-1)).astype('uint8')).resize(target_size)\n",
    "# #     display(img)\n",
    "    \n",
    "# for idx in range(full_mask.shape[0]):\n",
    "#     img = Image.fromarray((np.stack([full_mask[idx]]*3, axis=-1) * 255).astype('uint8')).resize(target_size)\n",
    "#     display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22f96c-78b3-409a-9eef-9026fbbb2466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg",
   "language": "python",
   "name": "seg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
